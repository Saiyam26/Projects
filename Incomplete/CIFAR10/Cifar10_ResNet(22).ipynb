{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8523a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as tt\n",
    "import tarfile\n",
    "# from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e825ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_url = \"http://files.fast.ai/data/examples/cifar10.tgz\"\n",
    "# download_url(dataset_url, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43327fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
    "#     tar.extractall(path = './data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9feba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.listdir('data/cifar10/train')\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63e0d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/cifar10'\n",
    "\n",
    "dataset = ImageFolder(data_dir + '/train', transform = ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800eeb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "t_s = int(len(dataset)*0.8)\n",
    "v_s = int(len(dataset) - t_s)\n",
    "train_ds, val_ds = random_split(dataset, [t_s, v_s])\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f031cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dl:\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf79f4",
   "metadata": {},
   "source": [
    "# ConvNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d30c2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    #16,32,32\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    #16,16,16\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    #16,8,8\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    #16,4,4\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    #16,1,1\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abec2b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for x,y, in train_dl:\n",
    "    print(x.shape)\n",
    "    yb = model(x)\n",
    "    print(yb.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f290bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_loss(model, batch, loss_fn, opt=None, metrics=None):\n",
    "    x, y = batch\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    met = None\n",
    "    if metrics is not None:\n",
    "        met = metrics(y_pred, y)\n",
    "    \n",
    "    return loss, len(x), met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95617589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_dl, loss_fn, metrics=None):\n",
    "    with torch.no_grad():\n",
    "        losses = 0\n",
    "        total = 0\n",
    "        if metrics is not None:\n",
    "            mets = 0\n",
    "        for batch in val_dl:\n",
    "            loss, sz, met = batch_loss(model, batch, loss_fn, metrics=metrics)\n",
    "            losses+=loss*sz\n",
    "            total+=sz\n",
    "            if metrics is not None:\n",
    "                mets+=met*sz\n",
    "    return losses/total, mets/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y):\n",
    "    _, preds = torch.max(y_pred, dim=1)\n",
    "    return (torch.sum(preds==y)).item()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1373cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_dl, val_dl, epochs, loss_fn, lr, opt_fn=torch.optim.Adam, metrics=None):\n",
    "    opt = opt_fn(model.parameters(), lr = lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in train_dl:\n",
    "            batch_loss(model, batch, loss_fn, opt, metrics)\n",
    "        \n",
    "        model.eval()\n",
    "        loss, mets = evaluate(model, val_dl, loss_fn, metrics)\n",
    "        print(f'Epoch {epoch+1}/{epochs} :\\nLoss: {loss}  {metrics.__name__}: {mets}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, train_dl, val_dl, 5, F.cross_entropy, 0.005, metrics = accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2a6799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ImageFolder(data_dir + '/test', transform = ToTensor())\n",
    "\n",
    "# def predict(img, classes):\n",
    "#     img = img.unsqueeze(0)\n",
    "#     yb = model(img)\n",
    "#     _, preds = torch.max(yb, dim=0)\n",
    "#     return classes[preds[0].item()]\n",
    "\n",
    "# img, label = test_ds[8755]\n",
    "# plt.imshow(img.permute(1,2,0))\n",
    "# print(predict(img, dataset.classes))\n",
    "# print(dataset.classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7cde1c",
   "metadata": {},
   "source": [
    "Failure training!\n",
    "55% acc(false), with only airplane as predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa03a28",
   "metadata": {},
   "source": [
    "# ResNets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed03fa4",
   "metadata": {},
   "source": [
    "hopefully get betters results.\n",
    "Will be using test set as validation set for more training data, sorry ://"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12154a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/cifar10'\n",
    "\n",
    "# will find later, ((mean_r),(mean_g),(mean_b)),((stdev_r),(stdev_g),(stdev_b))\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d27558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = tt.Compose([tt.RandomCrop(32, padding=4, padding_mode = 'reflect'),\n",
    "                         tt.RandomHorizontalFlip(),\n",
    "                         tt.ToTensor(),\n",
    "                         tt.Normalize(*stats)])\n",
    "\n",
    "val_tfms = tt.Compose([tt.ToTensor(),\n",
    "                       tt.Normalize(*stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c9f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageFolder(data_dir + '/train', train_tfms)\n",
    "val_ds = ImageFolder(data_dir + '/test', val_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a634a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle = True,\n",
    "                      num_workers = 8, pin_memory = True)\n",
    "val_dl = DataLoader(val_ds, batch_size, shuffle = True,\n",
    "                    num_workers = 8, pin_memory = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c984b9",
   "metadata": {},
   "source": [
    "## making the WideResNet (general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f5389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(ni, nf, stride=1, k_s=3):\n",
    "    return nn.Conv2d(ni, nf, kernel_size = k_s, stride = stride, padding = k_s//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a800176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_relu_conv(ni, nf):\n",
    "    return nn.Sequential(nn.BatchNorm2d(ni),\n",
    "                         nn.ReLU(inplace=True),\n",
    "                         conv2d(ni, nf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "386cc0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=1):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm2d(ni)\n",
    "        self.conv1 = conv2d(ni, nf, stride)\n",
    "        self.conv2 = bn_relu_conv(nf,nf)\n",
    "        self.shortcut = lambda x:x\n",
    "        if ni != nf:\n",
    "            self.shortcut = conv2d(ni, nf, stride, 1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn(x), inplace=True)\n",
    "        y = self.shortcut(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x) * 0.2\n",
    "        return x.add(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afa32cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_group(N, ni, nf, stride):\n",
    "    start = ResidualBlock(ni, nf, stride)\n",
    "    end = [ResidualBlock(nf,nf) for _ in range(1,N)]\n",
    "    return [start] + end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb8889f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def forward(self, x): return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2beaded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, n_groups, N, n_classes, k=1, n_start=16):\n",
    "        super().__init__()\n",
    "        layers = [conv2d(3, n_start)]\n",
    "        n_channels = [n_start]\n",
    "        \n",
    "        for i in range(n_groups):\n",
    "            n_channels.append(n_start*(2**i)*k)\n",
    "            stride = 2 if i>0 else 1\n",
    "            layers += make_group(N, n_channels[i], n_channels[i+1], stride)\n",
    "            \n",
    "        layers += [nn.BatchNorm2d(n_channels[-1]),\n",
    "                   nn.ReLU(inplace=True),\n",
    "                   nn.AdaptiveAvgPool2d(1),\n",
    "                   Flatten(),\n",
    "                   nn.Linear(n_channels[-1], n_classes)]\n",
    "        \n",
    "        self.features = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "176ff0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrn_22():\n",
    "    return WideResNet(3, 2, 10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57436ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = wrn_22()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee26b06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WideResNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ResidualBlock(\n",
       "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(16, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (shortcut): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (shortcut): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (shortcut): Conv2d(192, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): AdaptiveAvgPool2d(output_size=1)\n",
       "    (10): Flatten()\n",
       "    (11): Linear(in_features=384, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5aa9b836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('WRN_22.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04fd43d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.9534, -4.9738, -4.3437, -3.0710, -5.0124, -3.6364, -5.1273, -5.2035,\n",
       "         -6.4251, -4.9235]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = val_ds[6578]\n",
    "y = model(img.unsqueeze(0))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1342ec72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0557, 0.0546, 0.1025, 0.3661, 0.0525, 0.2080, 0.0468, 0.0434, 0.0128,\n",
      "        0.0574], grad_fn=<MaxBackward0>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "a, b = torch.max(F.softmax(y, dim=1), dim=0)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5944f2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WideResNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ResidualBlock(\n",
       "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(16, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (shortcut): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (shortcut): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (shortcut): Conv2d(192, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): AdaptiveAvgPool2d(output_size=1)\n",
       "    (10): Flatten()\n",
       "    (11): Linear(in_features=384, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f136148e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13a883130>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ee74f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "732d3fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pred(img):\n",
    "    img = img.unsqueeze(0)\n",
    "    yb = model(img)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    return preds[0].item()\n",
    "\n",
    "pred(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa27167e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1569, 0.1804, 0.1647,  ..., 0.0980, 0.0863, 0.0824],\n",
       "         [0.1843, 0.1961, 0.1608,  ..., 0.0941, 0.0824, 0.0863],\n",
       "         [0.2078, 0.2000, 0.1725,  ..., 0.0902, 0.0824, 0.0902],\n",
       "         ...,\n",
       "         [0.0706, 0.1020, 0.1294,  ..., 0.1882, 0.1647, 0.1647],\n",
       "         [0.0784, 0.1176, 0.1294,  ..., 0.1647, 0.1647, 0.1608],\n",
       "         [0.0824, 0.0902, 0.0902,  ..., 0.1490, 0.1490, 0.1490]],\n",
       "\n",
       "        [[0.1882, 0.2118, 0.2000,  ..., 0.1529, 0.1412, 0.1412],\n",
       "         [0.2000, 0.2235, 0.1961,  ..., 0.1490, 0.1373, 0.1333],\n",
       "         [0.2157, 0.2275, 0.2078,  ..., 0.1451, 0.1333, 0.1255],\n",
       "         ...,\n",
       "         [0.0902, 0.1294, 0.1725,  ..., 0.2235, 0.2039, 0.2118],\n",
       "         [0.0980, 0.1490, 0.1725,  ..., 0.1961, 0.2000, 0.2039],\n",
       "         [0.1020, 0.1255, 0.1294,  ..., 0.1882, 0.1882, 0.1882]],\n",
       "\n",
       "        [[0.1843, 0.2157, 0.1843,  ..., 0.1569, 0.1412, 0.1294],\n",
       "         [0.1922, 0.2275, 0.1765,  ..., 0.1529, 0.1373, 0.1255],\n",
       "         [0.2039, 0.2275, 0.1882,  ..., 0.1490, 0.1373, 0.1255],\n",
       "         ...,\n",
       "         [0.0667, 0.0902, 0.1255,  ..., 0.1804, 0.1608, 0.1647],\n",
       "         [0.0745, 0.1098, 0.1255,  ..., 0.1529, 0.1569, 0.1569],\n",
       "         [0.0784, 0.0863, 0.0863,  ..., 0.1451, 0.1451, 0.1412]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, lab = test_ds[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "908c7c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3107a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basic_data import DataBunch\n",
    "from fastai.train import Learner\n",
    "from fastai.metrics import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7accff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch.create(train_ds, val_ds, bs=batch_size, path = data_dir)\n",
    "learner = Learner(data, model, loss_func = F.cross_entropy, metrics= [accuracy])\n",
    "learner.clip = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f39edb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      2.56% [5/195 01:16<48:09 2.3353]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f01cf5c6afa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/ds/lib/python3.8/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(learn, start_lr, end_lr, num_it, stop_div, wd)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_distrib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,\n",
      "\u001b[0;32m~/miniforge3/envs/ds/lib/python3.8/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ds/lib/python3.8/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ds/lib/python3.8/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ds/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ds/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4440357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da99a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
